# 构建合成器基本框架

## 序

基于：

[JUCE: Tutorial: Build a sine wave synthesiser](https://docs.juce.com/master/tutorial_sine_synth.html)

[JUCE合成器设计-①认识Synthesiser Class | 香芋派Taro (taropie0224.github.io)](https://taropie0224.github.io/2022/01/27/JUCE合成器设计-①认识Synthesiser Class/)

前者是基于 `Application` 框架的。而后者是直接基于 `Plugin` 框架的，更易 ~~copy~~ 学习一点。

而且其实前者是使用 `AudioSource` 作为基类，后者直接是 `Synthesizer` 相关类作为基类。

本篇主要介绍：

+ 写 `voice` 和 `sound` 类构建振荡器 (这里叫声源更好) 框架
+ 写出合成器在 `Processor` 和 `Editor` 中的基本框架



## 框架选择

### 项目类型

选择 `Plugin - Basic` .

### 插件类型

勾选 `Plugin is a synth` 和 `Plugin MIDI input` .

### 模块选择

记得勾选 `juce_dsp` (这意味着你已经认可 JUCE 的 GPL 许可证).



## SynthSound 类

我们的 `Sound` 类非常简单，它甚至不需要包含任何数据。它只需要报告此声音是否应在特定 MIDI 通道以及该通道上的特定音符或音符范围上播放。在我们的简单示例中，它只返回 和 函数。

*如上所述， `Sound` 类可能是**存储创建声音所需的数据（如波表）**的位置。

```cpp
//SynthSound.h
#pragma once

#include <JuceHeader.h>

class SynthSound : public juce::SynthesiserSound
{
public:
    bool appliesToNote(int midiNoteNumber) override { return true; }
    bool appliesToChannel(int midiChannel) override { return true; }
};
```



## SynthVoice 类

继承自 `SynthesizerVoice` 类。这个类很抽象嗷，要覆写的东西有点多：

```cpp
//SynthVoice.h
#pragma once

#include <JuceHeader.h>
#include "SynthSound.h"

class SynthVoice : public juce::SynthesiserVoice
{
public:
    bool canPlaySound (juce::SynthesiserSound* sound) override;
    void startNote (int midiNoteNumber, float velocity, juce::SynthesiserSound* sound, int currentPitchWheelPosition) override;
    void stopNote (float velocity, bool allowTailOff) override;
    void controllerMoved (int controllerNumber, int newControllerValue) override;
    void pitchWheelMoved (int newPitchWheelValue) override;
    void renderNextBlock (juce::AudioBuffer< float > &outputBuffer, int startSample, int numSamples) override;
    void prepareToPlay (double sampleRate, int samplesPerBlock, int outputChannels);
private: //[1]
    //...
    bool isPrepared = false; //[2]
};
```

**[1]** prepareToPlay 不是基类虚函数，但我们需要自定义一个来作初始化。

**[2]** isPrepared 防止未初始化时调用渲染函数。

然后在 `.cpp` 里写出实现的框架：


```cpp
//SynthVoice.cpp
#include "SynthVoice.h"

bool SynthVoice::canPlaySound (juce::SynthesiserSound* sound)
{
    return dynamic_cast<juce::SynthesiserSound*>(sound) != nullptr;
    //如果可以运行，返回true
}

void SynthVoice::startNote (int midiNoteNumber, float velocity, juce::SynthesiserSound* sound, int currentPitchWheelPosition)
{

}

void SynthVoice::stopNote (float velocity, bool allowTailOff)
{

}

void SynthVoice::controllerMoved (int controllerNumber, int newControllerValue)
{
    
}

void SynthVoice::pitchWheelMoved (int newPitchWheelValue)
{
    
}

void SynthVoice::renderNextBlock (juce::AudioBuffer< float > &outputBuffer, int startSample, int numSamples)
{

}
```



## 与 Processor 交互

### 初始化

先定义一个 `juce::Synthesizer` 类实例吧：

```cpp
//PluginProcessor.h
private:
    juce::Synthesiser synth;
    
    //==============================================================================
    JUCE_DECLARE_NON_COPYABLE_WITH_LEAK_DETECTOR (SynthTutorialAudioProcessor)
};
```

为 `synth` 添加一个 `sound` 和 `voice`：

```cpp
//PluginProcessor.cpp
SynthTutorialAudioProcessor::SynthTutorialAudioProcessor()
#ifndef JucePlugin_PreferredChannelConfigurations
     : AudioProcessor (BusesProperties()
                     #if ! JucePlugin_IsMidiEffect
                      #if ! JucePlugin_IsSynth
                       .withInput  ("Input",  juce::AudioChannelSet::stereo(), true)
                      #endif
                       .withOutput ("Output", juce::AudioChannelSet::stereo(), true)
                     #endif
                       )
#endif
{
    synth.addSound(new SynthSound());
    synth.addVoice(new SynthVoice());
}
```

还要告诉 `synth` 采样率信息以初始化。

这一步注意**不要在 `Processor` 的构造函数内进行**，因为此时 `Processor` 的采样率信息害妹初始化完毕。

所以像这样用到 `Processor` 信息的初始化，请在 `prepare to play(...)` 函数中进行：

```cpp
//PluginProcessor.cpp
//...
void SynthTutorialAudioProcessor::prepareToPlay (double sampleRate, int samplesPerBlock)
{
    synth.setCurrentPlaybackSampleRate(getSampleRate()));  //设定synth的samplerate
}
//...
```

### 处理方法框架

合成器的处理方式可以不同，它可以是按 `voice` 去枚举，再应用 `Osc`，`ADSR`，`LFO` 等要素，最后再通过它自身的 `.render(...)` 函数渲染信号。

```cpp
//PluginProcessor.cpp
...
void SynthTutorialAudioProcessor::processBlock (juce::AudioBuffer<float>& buffer, juce::MidiBuffer& midiMessages)
{
    juce::ScopedNoDenormals noDenormals;
    auto totalNumInputChannels  = getTotalNumInputChannels();
    auto totalNumOutputChannels = getTotalNumOutputChannels();

    for (auto i = totalNumInputChannels; i < totalNumOutputChannels; ++i)
        buffer.clear (i, 0, buffer.getNumSamples());
    
    for (int i = 0; i < synth.getNumVoices(); ++i)
    {
        if (auto voice = dynamic_cast<juce::SynthesiserVoice*>(synth.getVoice(i)));
        {
            // Osc
            // ADSR
            // LFO
        }
    }
    
    synth.renderNextBlock(buffer, midiMessages, 0, buffer.getNumSamples());
}
...
```

所以小伙子，处理流程别被局限了，这里是 `C++` ！
